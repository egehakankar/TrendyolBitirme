[0m[[0m[0mdebug[0m] [0m[0m> Exec(run, Some(6615188d-d242-444c-81aa-b0bc49ca7d67), Some(CommandSource(console0)))[0m
[0m[[0m[0mdebug[0m] [0m[0mEvaluating tasks: Compile / run[0m
[0m[[0m[0mdebug[0m] [0m[0mRunning task... Cancel: bloop.integrations.sbt.Offloader$$anon$1@7962c1d5, check cycles: false, forcegc: true[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/taskStart, {"taskId":{"id":"61","parents":[]},"eventTime":1613739824922,"message":"Compiling trendyolspark","dataKind":"compile-task","data":{"target":{"uri":"file:/C:/Users/Hakan/OneDrive/Desktop/Lessons/4.%20Year/2nd%20Semester/trendyol/trendyolSpark/trendyolSpark/#trendyolspark/Compile"}}})[0m
[0m[[0m[0minfo[0m] [0m[0mcompiling 1 Scala source to C:\Users\Hakan\OneDrive\Desktop\Lessons\4. Year\2nd Semester\trendyol\trendyolSpark\trendyolSpark\target\scala-2.11\classes ...[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/logMessage, {"type":3,"message":"compiling 1 Scala source to C:\\Users\\Hakan\\OneDrive\\Desktop\\Lessons\\4. Year\\2nd Semester\\trendyol\\trendyolSpark\\trendyolSpark\\target\\scala-2.11\\classes ..."})[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/publishDiagnostics, {"textDocument":{"uri":"file:///C:/Users/Hakan/OneDrive/Desktop/Lessons/4.%20Year/2nd%20Semester/trendyol/trendyolSpark/trendyolSpark/src/main/scala/spark/SparkAllJobs.scala"},"buildTarget":{"uri":"file:/C:/Users/Hakan/OneDrive/Desktop/Lessons/4.%20Year/2nd%20Semester/trendyol/trendyolSpark/trendyolSpark/#trendyolspark/Compile"},"diagnostics":[{"range":{"start":{"line":52,"character":20},"end":{"line":52,"character":21}},"severity":1,"source":"sbt","message":"overloaded method value createDataFrame with alternatives:\n  [A <: Product](data: Seq[A])(implicit evidence$3: reflect.runtime.universe.TypeTag[A])org.apache.spark.sql.DataFrame <and>\n  [A <: Product](rdd: org.apache.spark.rdd.RDD[A])(implicit evidence$2: reflect.runtime.universe.TypeTag[A])org.apache.spark.sql.DataFrame\n cannot be applied to (Unit)"}],"reset":false})[0m
[0m[[0m[31merror[0m] [0m[0mC:\Users\Hakan\OneDrive\Desktop\Lessons\4. Year\2nd Semester\trendyol\trendyolSpark\trendyolSpark\src\main\scala\spark\SparkAllJobs.scala:53:21: overloaded method value createDataFrame with alternatives:[0m
[0m[[0m[31merror[0m] [0m[0m  [A <: Product](data: Seq[A])(implicit evidence$3: reflect.runtime.universe.TypeTag[A])org.apache.spark.sql.DataFrame <and>[0m
[0m[[0m[31merror[0m] [0m[0m  [A <: Product](rdd: org.apache.spark.rdd.RDD[A])(implicit evidence$2: reflect.runtime.universe.TypeTag[A])org.apache.spark.sql.DataFrame[0m
[0m[[0m[31merror[0m] [0m[0m cannot be applied to (Unit)[0m
[0m[[0m[31merror[0m] [0m[0m    val j3t = spark.createDataFrame(j3).toDF("product_id", "order_date", "price")[0m
[0m[[0m[31merror[0m] [0m[0m                    ^[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/logMessage, {"type":1,"message":"C:\\Users\\Hakan\\OneDrive\\Desktop\\Lessons\\4. Year\\2nd Semester\\trendyol\\trendyolSpark\\trendyolSpark\\src\\main\\scala\\spark\\SparkAllJobs.scala:53:21: overloaded method value createDataFrame with alternatives:\n  [A <: Product](data: Seq[A])(implicit evidence$3: reflect.runtime.universe.TypeTag[A])org.apache.spark.sql.DataFrame <and>\n  [A <: Product](rdd: org.apache.spark.rdd.RDD[A])(implicit evidence$2: reflect.runtime.universe.TypeTag[A])org.apache.spark.sql.DataFrame\n cannot be applied to (Unit)"})[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/logMessage, {"type":1,"message":"    val j3t = spark.createDataFrame(j3).toDF(\"product_id\", \"order_date\", \"price\")"})[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/logMessage, {"type":1,"message":"                    ^"})[0m
[0m[[0m[31merror[0m] [0m[0mone error found[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/logMessage, {"type":1,"message":"one error found"})[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/publishDiagnostics, {"textDocument":{"uri":"file:///C:/Users/Hakan/OneDrive/Desktop/Lessons/4.%20Year/2nd%20Semester/trendyol/trendyolSpark/trendyolSpark/src/main/scala/spark/SparkAllJobs.scala"},"buildTarget":{"uri":"file:/C:/Users/Hakan/OneDrive/Desktop/Lessons/4.%20Year/2nd%20Semester/trendyol/trendyolSpark/trendyolSpark/#trendyolspark/Compile"},"diagnostics":[{"range":{"start":{"line":52,"character":20},"end":{"line":52,"character":21}},"severity":1,"source":"sbt","message":"overloaded method value createDataFrame with alternatives:\n  [A <: Product](data: Seq[A])(implicit evidence$3: reflect.runtime.universe.TypeTag[A])org.apache.spark.sql.DataFrame <and>\n  [A <: Product](rdd: org.apache.spark.rdd.RDD[A])(implicit evidence$2: reflect.runtime.universe.TypeTag[A])org.apache.spark.sql.DataFrame\n cannot be applied to (Unit)"}],"reset":true})[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/taskFinish, {"taskId":{"id":"61","parents":[]},"eventTime":1613739825407,"message":"Compiled trendyolspark","status":2,"dataKind":"compile-report","data":{"target":{"uri":"file:/C:/Users/Hakan/OneDrive/Desktop/Lessons/4.%20Year/2nd%20Semester/trendyol/trendyolSpark/trendyolSpark/#trendyolspark/Compile"},"errors":1,"warnings":0,"time":485}})[0m
[0m[[0m[31merror[0m] [0m[0m(Compile / [31mcompileIncremental[0m) Compilation failed[0m
[0m[[0m[0mdebug[0m] [0m[0mjsonRpcNotify: JsonRpcNotificationMessage(2.0, build/logMessage, {"type":1,"message":"(Compile / \u001b[31mcompileIncremental\u001b[0m) Compilation failed"})[0m
[0m[[0m[31merror[0m] [0m[0mTotal time: 1 s, completed Feb 19, 2021, 4:03:45 PM[0m
[0m[[0m[0mdebug[0m] [0m[0m> Exec(shell, None, None)[0m
